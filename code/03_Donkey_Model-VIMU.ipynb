{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dabfb61-8e59-4b51-a5cb-b02d7f12b240",
   "metadata": {},
   "source": [
    "# Donkey Car Attempt\n",
    "\n",
    "My attempts to build a CNN from scratch are hitting walls. I am going to try out a model suggested on the [Donkey Car Webpage](https://docs.donkeycar.com/dev_guide/model/), to establish a \"baseline\" (very broadly) of sorts to which I can compate the \"custom\" models of my own design.\n",
    "\n",
    "Steps:\n",
    "1. Establish modeling parameters\n",
    "1. Split data into training and testing sets\n",
    "1. Scale telemetry data with scikitlearn's minmaxscaler or standardscaler\n",
    "1. Save the scaler to scale fresh driving input data for inferences\n",
    "1. Define methods to construct, fit, plot, and save a model\n",
    "1. Fit, save, and plot a constructed model with a range of batch sizes\n",
    "1. Save the model and record path and metrics/parameters in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a186988-1c64-48d0-984a-6c15b299587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import sklearn.metrics as metrics\n",
    "from os.path import exists\n",
    "\n",
    "from modeling_methods import run_model, plot_metrics, save_model, create_donkey_vimu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.metrics import MAE, MSE, RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db63f4ff-a88a-47b4-9400-b2c706a22932",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directories\n",
    "working_date = '11_12_2021'\n",
    "working_time = '19_28_18'\n",
    "\n",
    "## Directories\n",
    "data_directory = f'../data/{working_date}/{working_time}'\n",
    "model_directory = f'../models/{working_date}/{working_time}'\n",
    "\n",
    "## File paths\n",
    "cam_input_dataset_file = f'{data_directory}/X_img.npy'\n",
    "telem_input_dataset_file = f'{data_directory}/X_telem.pkl'\n",
    "target_dataset_file = f'{data_directory}/y.npy'\n",
    "\n",
    "## Parameters\n",
    "scaler = 'standard' # ['minmax', 'standard']\n",
    "dual_outputs = True\n",
    "batch_sizes = [32, 64, 128, 256, 512, 1024]\n",
    "early_stop_patience = 5 # None for no stop\n",
    "epochs = 250\n",
    "\n",
    "create_model = create_donkey_vimu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395f538-7d20-41bd-ad43-903722c14353",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f5725-213b-4492-bc82-202c86181efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the datasets\n",
    "X_cam = np.load(cam_input_dataset_file)\n",
    "X_telem = pd.read_pickle(telem_input_dataset_file).to_numpy()\n",
    "y = np.load(target_dataset_file)\n",
    "\n",
    "## Split for dual output\n",
    "if dual_outputs:\n",
    "    y_steering = y[:, 0]\n",
    "    y_throttle = y[:, 1]\n",
    "\n",
    "## Check Shape\n",
    "X_cam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024459d-2092-4448-b76b-1163bac9130b",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30558a03-f187-479b-9fea-eea61290f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if dual_outputs:\n",
    "    datasets = train_test_split(X_cam, X_telem, y_steering, y_throttle, test_size=0.1, random_state=0)\n",
    "else:\n",
    "    datasets = train_test_split(X_cam, X_telem, y, test_size=0.1, random_state=0)\n",
    "    \n",
    "X_cam_train = datasets[0]\n",
    "X_cam_test = datasets[1]\n",
    "X_telem_train = datasets[2]\n",
    "X_telem_test = datasets[3]\n",
    "y_train = datasets[4]\n",
    "y_test = datasets[5]\n",
    "    \n",
    "if dual_outputs:\n",
    "    y_st_train = datasets[4]\n",
    "    y_st_test = datasets[5]\n",
    "    y_th_train = datasets[6]\n",
    "    y_th_test = datasets[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001361f5-0f0a-496e-8e26-846e12c0be7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Scale IMU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b1e05-40e4-4cf0-986d-4b5094637c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = None\n",
    "scaler_file = None\n",
    "if scaler == 'minmax':\n",
    "    sc = MinMaxScaler() # default range: [0, 1]\n",
    "    scaler_file = f'{data_directory}/mm_scaler_{time.strftime(\"%m_%d_%H_%M\")}.pkl'\n",
    "elif scaler == 'standard':\n",
    "    sc = StandardScaler()\n",
    "    scaler_file = f'{data_directory}/ss_scaler_{time.strftime(\"%m_%d_%H_%M\")}.pkl'\n",
    "\n",
    "## Fit to then and transform training data\n",
    "X_telem_train_sc = sc.fit_transform(X_telem_train)\n",
    "## Transform testing data\n",
    "X_telem_test_sc = sc.transform(X_telem_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a507fa-f488-442a-bcc2-9943507140be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Save the Scaler for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8d37d-8624-4631-8246-f8079cb91f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Save as pickle\n",
    "pickle.dump(sc, open(scaler_file, 'wb'))\n",
    "\n",
    "## Print path\n",
    "scaler_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd46a7b-3435-4a05-afcc-274e3af58264",
   "metadata": {},
   "source": [
    "### Get Input Shape(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a58b8-4b6b-4123-b4ad-9a4a83df348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create variables\n",
    "cam_input_shape = X_cam_train[0].shape\n",
    "telem_input_shape = X_telem_train_sc[0].shape\n",
    "\n",
    "## Check telemetry input shape\n",
    "telem_input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ada31-38b8-4741-8e56-6c0c8038777b",
   "metadata": {},
   "source": [
    "## Model Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0febfbaa-d815-45d4-9c60-7c069f767e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = [X_cam_train, X_telem_train_sc]\n",
    "X_test = (X_cam_test, X_telem_test_sc)\n",
    "\n",
    "if dual_outputs:\n",
    "    y_train = (y_st_train, y_th_train)\n",
    "    y_test = (y_st_test, y_th_test)\n",
    "else:\n",
    "    y_train = y_train\n",
    "    y_test = y_test\n",
    "\n",
    "## Run models for each batch size\n",
    "print('---')\n",
    "for batch_size in batch_sizes:\n",
    "    print(f'Batch size {batch_size} start: {time.strftime(\"%H:%M:%S\")}')\n",
    "    model = create_model(cam_input_shape, telem_input_shape, dual_outputs)\n",
    "    model.compile(loss='mse', \n",
    "                  optimizer=Adam(learning_rate=0.0001), \n",
    "                  metrics=['mae', RootMeanSquaredError()])\n",
    "    model, results = run_model(model, X_train, y_train, X_test, y_test, \n",
    "                               batch_size, epochs,\n",
    "                              early_stop_patience=early_stop_patience)\n",
    "    model_path = save_model(model_directory, model, results, batch_size, \n",
    "                            dual_outputs, scaler_file)\n",
    "    history = {k: v for k, v in results.history.items()}\n",
    "    plot_metrics(history, batch_size, dual_outputs)\n",
    "    print(f'Batch size {batch_size} end:   {time.strftime(\"%H:%M:%S\")}')\n",
    "    print(f'Epochs run: {len(history[\"loss\"])}')\n",
    "    print(f'path: {model_path}')\n",
    "    print('---')\n",
    "# model_history.tail(len(batch_sizes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
